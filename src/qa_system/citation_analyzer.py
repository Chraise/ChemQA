import re
from typing import List, Dict, Any, Tuple
from collections import defaultdict
from src.utils.logger import logger


class CitationAnalyzer:
    """
    åˆ†æç­”æ¡ˆå¼•ç”¨çš„ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°é‡çš„å·¥å…·ç±»
    """
    
    def __init__(self):
        """åˆå§‹åŒ–å¼•ç”¨åˆ†æå™¨"""
        pass
    
    def analyze_citations(self, answer: str, context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æç­”æ¡ˆä¸­çš„å¼•ç”¨æƒ…å†µ
        
        Args:
            answer: åŸå§‹ç­”æ¡ˆæ–‡æœ¬
            context: ä¸Šä¸‹æ–‡ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            åŒ…å«å¼•ç”¨åˆ†æç»“æœçš„å­—å…¸
        """
        logger.info("å¼€å§‹åˆ†æç­”æ¡ˆå¼•ç”¨æƒ…å†µ")
        
        # 1. ç»Ÿè®¡ä¸Šä¸‹æ–‡ç‰‡æ®µæ€»æ•°
        total_context_chunks = len(context)
        
        # 2. æå–ç­”æ¡ˆä¸­çš„æ‰€æœ‰å¼•ç”¨æ ‡è®°
        citations_in_answer = self._extract_citations_from_answer(answer)
        
        # 3. åˆ†æå¼•ç”¨çš„ä¸Šä¸‹æ–‡ç‰‡æ®µ
        cited_chunks_analysis = self._analyze_cited_chunks(answer, context)
        
        # 4. è®¡ç®—å¼•ç”¨è¦†ç›–ç‡
        citation_coverage = self._calculate_coverage(cited_chunks_analysis, total_context_chunks)
        
        # 5. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        analysis_report = {
            "total_context_chunks": total_context_chunks,
            "citations_in_answer": citations_in_answer,
            "cited_chunks_analysis": cited_chunks_analysis,
            "citation_coverage": citation_coverage,
            "summary": self._generate_summary(cited_chunks_analysis, citation_coverage)
        }
        
        logger.info(f"å¼•ç”¨åˆ†æå®Œæˆ: æ€»ç‰‡æ®µ{total_context_chunks}ä¸ª, å¼•ç”¨ç‰‡æ®µ{citation_coverage['cited_count']}ä¸ª")
        return analysis_report
    
    def _extract_citations_from_answer(self, answer: str) -> List[str]:
        """
        ä»ç­”æ¡ˆä¸­æå–æ‰€æœ‰å¼•ç”¨æ ‡è®°
        
        Args:
            answer: ç­”æ¡ˆæ–‡æœ¬
            
        Returns:
            å¼•ç”¨æ ‡è®°åˆ—è¡¨
        """
        # åŒ¹é…å„ç§å¼•ç”¨æ ¼å¼
        citation_patterns = [
            r'\[Ref\s+([^\]]+)\]',  # [Ref xxx]
            r'\[(\d+)\]',          # [1], [2], [3]...
            r'\[([^\]]+)\]'        # å…¶ä»–æ ¼å¼çš„å¼•ç”¨
        ]
        
        citations = []
        for pattern in citation_patterns:
            matches = re.findall(pattern, answer)
            citations.extend(matches)
        
        # å»é‡å¹¶è¿”å›
        return list(set(citations))
    
    def _analyze_cited_chunks(self, answer: str, context: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        åˆ†æè¢«å¼•ç”¨çš„ä¸Šä¸‹æ–‡ç‰‡æ®µ
        
        Args:
            answer: ç­”æ¡ˆæ–‡æœ¬
            context: ä¸Šä¸‹æ–‡ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            å¼•ç”¨åˆ†æç»“æœ
        """
        # å»ºç«‹ä¸Šä¸‹æ–‡ç‰‡æ®µçš„æ˜ å°„
        chunk_mapping = {}
        for i, doc in enumerate(context):
            # è·å–ç‰‡æ®µæ ‡è¯†ç¬¦
            chunk_id = None
            if isinstance(doc, dict):
                if 'chunk_index' in doc:
                    chunk_id = f"chunk_{doc['chunk_index']}"
                elif 'source' in doc:
                    chunk_id = f"source_{doc['source']}"
                else:
                    chunk_id = f"chunk_{i}"
            
            chunk_mapping[chunk_id] = {
                "index": i,
                "source": doc.get('source', 'unknown'),
                "chunk_index": doc.get('chunk_index', i),
                "text_preview": doc.get('text', '')[:100] + "..." if doc.get('text') else "",
                "cited": False,
                "citation_count": 0
            }
        
        # æ£€æŸ¥æ¯ä¸ªç‰‡æ®µæ˜¯å¦è¢«å¼•ç”¨
        cited_chunks = []
        for chunk_id, chunk_info in chunk_mapping.items():
            # æ£€æŸ¥ç­”æ¡ˆä¸­æ˜¯å¦åŒ…å«å¯¹è¯¥ç‰‡æ®µçš„å¼•ç”¨
            citation_patterns = [
                f"[Ref {chunk_info['chunk_index']}]",
                f"[Ref {chunk_info['source']}]",
                f"[Ref {chunk_id}]"
            ]
            
            for pattern in citation_patterns:
                if pattern in answer:
                    chunk_info['cited'] = True
                    chunk_info['citation_count'] = answer.count(pattern)
                    cited_chunks.append(chunk_info)
                    break
        
        return {
            "total_chunks": len(context),
            "cited_chunks": cited_chunks,
            "cited_count": len(cited_chunks),
            "chunk_mapping": chunk_mapping
        }
    
    def _calculate_coverage(self, cited_chunks_analysis: Dict[str, Any], total_chunks: int) -> Dict[str, Any]:
        """
        è®¡ç®—å¼•ç”¨è¦†ç›–ç‡
        
        Args:
            cited_chunks_analysis: å¼•ç”¨åˆ†æç»“æœ
            total_chunks: æ€»ç‰‡æ®µæ•°
            
        Returns:
            è¦†ç›–ç‡ç»Ÿè®¡
        """
        cited_count = cited_chunks_analysis['cited_count']
        coverage_percentage = (cited_count / total_chunks * 100) if total_chunks > 0 else 0
        
        return {
            "cited_count": cited_count,
            "total_count": total_chunks,
            "coverage_percentage": round(coverage_percentage, 2),
            "unused_count": total_chunks - cited_count
        }
    
    def _generate_summary(self, cited_chunks_analysis: Dict[str, Any], coverage: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆåˆ†ææ‘˜è¦
        
        Args:
            cited_chunks_analysis: å¼•ç”¨åˆ†æç»“æœ
            coverage: è¦†ç›–ç‡ç»Ÿè®¡
            
        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        summary = f"å¼•ç”¨åˆ†ææ‘˜è¦:\n"
        summary += f"- æ€»ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°: {coverage['total_count']}\n"
        summary += f"- è¢«å¼•ç”¨çš„ç‰‡æ®µæ•°: {coverage['cited_count']}\n"
        summary += f"- æœªä½¿ç”¨çš„ç‰‡æ®µæ•°: {coverage['unused_count']}\n"
        summary += f"- å¼•ç”¨è¦†ç›–ç‡: {coverage['coverage_percentage']}%\n"
        
        if cited_chunks_analysis['cited_chunks']:
            summary += f"- è¢«å¼•ç”¨çš„ç‰‡æ®µæ¥æº: "
            sources = list(set(chunk['source'] for chunk in cited_chunks_analysis['cited_chunks']))
            summary += ", ".join(sources[:5])  # åªæ˜¾ç¤ºå‰5ä¸ªæ¥æº
            if len(sources) > 5:
                summary += f" ç­‰{len(sources)}ä¸ªæ¥æº"
        
        return summary
    
    def print_detailed_report(self, analysis_report: Dict[str, Any]) -> None:
        """
        æ‰“å°è¯¦ç»†çš„åˆ†ææŠ¥å‘Š
        
        Args:
            analysis_report: åˆ†ææŠ¥å‘Š
        """
        print("\n" + "="*60)
        print("ç­”æ¡ˆå¼•ç”¨ä¸Šä¸‹æ–‡ç‰‡æ®µåˆ†ææŠ¥å‘Š")
        print("="*60)
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
        print(f"   æ€»ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°: {analysis_report['total_context_chunks']}")
        print(f"   è¢«å¼•ç”¨çš„ç‰‡æ®µæ•°: {analysis_report['citation_coverage']['cited_count']}")
        print(f"   å¼•ç”¨è¦†ç›–ç‡: {analysis_report['citation_coverage']['coverage_percentage']}%")
        
        # å¼•ç”¨è¯¦æƒ…
        if analysis_report['cited_chunks_analysis']['cited_chunks']:
            print(f"\nğŸ“š è¢«å¼•ç”¨çš„ç‰‡æ®µè¯¦æƒ…:")
            for i, chunk in enumerate(analysis_report['cited_chunks_analysis']['cited_chunks'], 1):
                print(f"   {i}. æ¥æº: {chunk['source']}")
                print(f"      ç‰‡æ®µç´¢å¼•: {chunk['chunk_index']}")
                print(f"      å¼•ç”¨æ¬¡æ•°: {chunk['citation_count']}")
                print(f"      å†…å®¹é¢„è§ˆ: {chunk['text_preview']}")
                print()
        
        # æœªä½¿ç”¨çš„ç‰‡æ®µ
        unused_count = analysis_report['citation_coverage']['unused_count']
        if unused_count > 0:
            print(f"\nâš ï¸  æœªä½¿ç”¨çš„ç‰‡æ®µ:")
            print(f"   æœ‰ {unused_count} ä¸ªä¸Šä¸‹æ–‡ç‰‡æ®µæœªè¢«å¼•ç”¨")
            
            # æ˜¾ç¤ºä¸€äº›æœªä½¿ç”¨çš„ç‰‡æ®µ
            unused_chunks = []
            for chunk_id, chunk_info in analysis_report['cited_chunks_analysis']['chunk_mapping'].items():
                if not chunk_info['cited']:
                    unused_chunks.append(chunk_info)
            
            for i, chunk in enumerate(unused_chunks[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"   {i}. æ¥æº: {chunk['source']}")
                print(f"      å†…å®¹é¢„è§ˆ: {chunk['text_preview']}")
                print()
            
            if len(unused_chunks) > 3:
                print(f"   ... è¿˜æœ‰ {len(unused_chunks) - 3} ä¸ªæœªä½¿ç”¨çš„ç‰‡æ®µ")
        
        # æ‘˜è¦
        print(f"\nğŸ“‹ åˆ†ææ‘˜è¦:")
        print(analysis_report['summary'])
        
        print("\n" + "="*60)
    
    def save_analysis_to_file(self, analysis_report: Dict[str, Any], filename: str = "citation_analysis.txt") -> None:
        """
        å°†åˆ†æç»“æœä¿å­˜åˆ°æ–‡ä»¶
        
        Args:
            analysis_report: åˆ†ææŠ¥å‘Š
            filename: æ–‡ä»¶å
        """
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write("ç­”æ¡ˆå¼•ç”¨ä¸Šä¸‹æ–‡ç‰‡æ®µåˆ†ææŠ¥å‘Š\n")
                f.write("="*50 + "\n\n")
                
                # å†™å…¥æ‘˜è¦
                f.write(analysis_report['summary'] + "\n\n")
                
                # å†™å…¥è¯¦ç»†ç»Ÿè®¡
                f.write("è¯¦ç»†ç»Ÿè®¡:\n")
                f.write(f"æ€»ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°: {analysis_report['total_context_chunks']}\n")
                f.write(f"è¢«å¼•ç”¨çš„ç‰‡æ®µæ•°: {analysis_report['citation_coverage']['cited_count']}\n")
                f.write(f"å¼•ç”¨è¦†ç›–ç‡: {analysis_report['citation_coverage']['coverage_percentage']}%\n\n")
                
                # å†™å…¥è¢«å¼•ç”¨çš„ç‰‡æ®µè¯¦æƒ…
                if analysis_report['cited_chunks_analysis']['cited_chunks']:
                    f.write("è¢«å¼•ç”¨çš„ç‰‡æ®µè¯¦æƒ…:\n")
                    for i, chunk in enumerate(analysis_report['cited_chunks_analysis']['cited_chunks'], 1):
                        f.write(f"{i}. æ¥æº: {chunk['source']}\n")
                        f.write(f"   ç‰‡æ®µç´¢å¼•: {chunk['chunk_index']}\n")
                        f.write(f"   å¼•ç”¨æ¬¡æ•°: {chunk['citation_count']}\n")
                        f.write(f"   å†…å®¹é¢„è§ˆ: {chunk['text_preview']}\n\n")
            
            logger.info(f"å¼•ç”¨åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {str(e)}")


def analyze_answer_citations(answer: str, context: List[Dict[str, Any]], 
                           print_report: bool = True, save_to_file: bool = False) -> Dict[str, Any]:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æç­”æ¡ˆå¼•ç”¨çš„ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°é‡
    
    Args:
        answer: ç­”æ¡ˆæ–‡æœ¬
        context: ä¸Šä¸‹æ–‡ç‰‡æ®µåˆ—è¡¨
        print_report: æ˜¯å¦æ‰“å°æŠ¥å‘Š
        save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
        
    Returns:
        åˆ†ææŠ¥å‘Šå­—å…¸
    """
    analyzer = CitationAnalyzer()
    analysis_report = analyzer.analyze_citations(answer, context)
    
    if print_report:
        analyzer.print_detailed_report(analysis_report)
    
    if save_to_file:
        analyzer.save_analysis_to_file(analysis_report)
    
    return analysis_report 