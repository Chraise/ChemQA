#!/usr/bin/env python3
"""
å¯¹æ¯”åˆ†æè„šæœ¬

æ¯”è¾ƒæœ‰æ— æœ¬åœ°æ–‡çŒ®åº“æ£€ç´¢åŠŸèƒ½çš„å·®å¼‚ï¼Œåˆ†æä¸¤ç§æ–¹æ³•çš„ä¼˜ç¼ºç‚¹ã€‚
"""

import sys
import os
import json
import time
from datetime import datetime
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from citation_analysis.citation_analyzer import CitationAnalyzer


class ComparisonAnalyzer:
    """å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.citation_analyzer = CitationAnalyzer()
        
        # å®šä¹‰è¾“å‡ºç›®å½•
        self.output_dir = Path("comparison_output")
        self.output_dir.mkdir(exist_ok=True)
        
        # å®šä¹‰è¾“å…¥ç›®å½•
        self.retrieval_dir = Path("qa_testing_output")  # æœ‰æ–‡çŒ®åº“æ£€ç´¢çš„ç»“æœ
        self.direct_api_dir = Path("direct_api_output")  # ç›´æ¥APIçš„ç»“æœ
        
        # å­˜å‚¨å¯¹æ¯”æ•°æ®
        self.comparison_data = []
    
    def load_test_results(self, directory: Path) -> dict:
        """åŠ è½½æµ‹è¯•ç»“æœ"""
        summary_file = directory / "summary.json"
        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def load_direct_api_results(self) -> dict:
        """åŠ è½½ç›´æ¥APIç»“æœ"""
        summary_file = self.direct_api_dir / "direct_api_summary.json"
        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def analyze_citations(self, answer_file: Path) -> dict:
        """åˆ†æå¼•ç”¨æƒ…å†µ"""
        try:
            with open(answer_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æå–ç­”æ¡ˆéƒ¨åˆ†ï¼ˆå»æ‰markdownæ ¼å¼ï¼‰
            if content.startswith('#'):
                # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç©ºè¡Œåçš„å†…å®¹
                lines = content.split('\n')
                for i, line in enumerate(lines):
                    if line.strip() == '' and i > 0:
                        answer = '\n'.join(lines[i+1:])
                        break
                else:
                    answer = content
            else:
                answer = content
            
            # åˆ†æå¼•ç”¨
            analysis = self.citation_analyzer.analyze_citations(answer)
            return analysis
        except Exception as e:
            print(f"åˆ†æå¼•ç”¨å¤±è´¥ {answer_file}: {str(e)}")
            return {"citation_count": 0, "context_fragments": 0}
    
    def compare_methods(self):
        """å¯¹æ¯”ä¸¤ç§æ–¹æ³•"""
        print("ğŸ” å¼€å§‹å¯¹æ¯”åˆ†æ...")
        
        # åŠ è½½ç»“æœ
        retrieval_results = self.load_test_results(self.retrieval_dir)
        direct_api_results = self.load_direct_api_results()
        
        if not retrieval_results or not direct_api_results:
            print("âŒ æ— æ³•åŠ è½½æµ‹è¯•ç»“æœï¼Œè¯·ç¡®ä¿ä¸¤ç§æ–¹æ³•éƒ½å·²è¿è¡Œå®Œæˆ")
            return
        
        print("âœ… æˆåŠŸåŠ è½½ä¸¤ç§æ–¹æ³•çš„æµ‹è¯•ç»“æœ")
        
        # åˆ†ææ¯ä¸ªé—®é¢˜çš„å¯¹æ¯”
        for i in range(1, 11):  # 10ä¸ªé—®é¢˜
            print(f"\nåˆ†æé—®é¢˜ {i}...")
            
            # åŠ è½½ä¸¤ç§æ–¹æ³•çš„ç­”æ¡ˆ
            retrieval_answer_file = self.retrieval_dir / f"answer_{i:02d}.md"
            direct_answer_file = self.direct_api_dir / f"direct_answer_{i:02d}.md"
            
            if not retrieval_answer_file.exists() or not direct_answer_file.exists():
                print(f"âš ï¸  é—®é¢˜ {i} çš„ç­”æ¡ˆæ–‡ä»¶ä¸å®Œæ•´ï¼Œè·³è¿‡")
                continue
            
            # åˆ†æå¼•ç”¨æƒ…å†µ
            retrieval_citations = self.analyze_citations(retrieval_answer_file)
            direct_citations = self.analyze_citations(direct_answer_file)
            
            # è·å–å¤„ç†æ—¶é—´
            retrieval_time = 0
            direct_time = 0
            
            for result in retrieval_results.get("detailed_results", []):
                if result.get("question_id") == i:
                    retrieval_time = result.get("processing_time", 0)
                    break
            
            for result in direct_api_results.get("detailed_results", []):
                if result.get("question_id") == i:
                    direct_time = result.get("processing_time", 0)
                    break
            
            # è®¡ç®—ç­”æ¡ˆé•¿åº¦
            with open(retrieval_answer_file, 'r', encoding='utf-8') as f:
                retrieval_length = len(f.read())
            
            with open(direct_answer_file, 'r', encoding='utf-8') as f:
                direct_length = len(f.read())
            
            # å­˜å‚¨å¯¹æ¯”æ•°æ®
            comparison_item = {
                "question_id": i,
                "retrieval": {
                    "processing_time": retrieval_time,
                    "answer_length": retrieval_length,
                    "citation_count": retrieval_citations.get("citation_count", 0),
                    "context_fragments": retrieval_citations.get("context_fragments", 0)
                },
                "direct_api": {
                    "processing_time": direct_time,
                    "answer_length": direct_length,
                    "citation_count": direct_citations.get("citation_count", 0),
                    "context_fragments": direct_citations.get("context_fragments", 0)
                }
            }
            
            self.comparison_data.append(comparison_item)
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        self.generate_comparison_report()
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.generate_comparison_charts()
        
        print(f"\nğŸ‰ å¯¹æ¯”åˆ†æå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {self.output_dir}")
    
    def generate_comparison_report(self):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        if not self.comparison_data:
            print("âŒ æ²¡æœ‰å¯¹æ¯”æ•°æ®å¯ç”ŸæˆæŠ¥å‘Š")
            return
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        retrieval_times = [item["retrieval"]["processing_time"] for item in self.comparison_data]
        direct_times = [item["direct_api"]["processing_time"] for item in self.comparison_data]
        
        retrieval_lengths = [item["retrieval"]["answer_length"] for item in self.comparison_data]
        direct_lengths = [item["direct_api"]["answer_length"] for item in self.comparison_data]
        
        retrieval_citations = [item["retrieval"]["citation_count"] for item in self.comparison_data]
        direct_citations = [item["direct_api"]["citation_count"] for item in self.comparison_data]
        
        retrieval_fragments = [item["retrieval"]["context_fragments"] for item in self.comparison_data]
        direct_fragments = [item["direct_api"]["context_fragments"] for item in self.comparison_data]
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = self.output_dir / "comparison_report.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("æœ‰æ— æ–‡çŒ®åº“æ£€ç´¢åŠŸèƒ½å¯¹æ¯”åˆ†ææŠ¥å‘Š\n")
            f.write("="*60 + "\n\n")
            
            f.write(f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¯¹æ¯”é—®é¢˜æ•°: {len(self.comparison_data)}\n\n")
            
            f.write("1. å¤„ç†æ—¶é—´å¯¹æ¯”\n")
            f.write("-" * 30 + "\n")
            f.write(f"æ–‡çŒ®åº“æ£€ç´¢å¹³å‡æ—¶é—´: {sum(retrieval_times)/len(retrieval_times):.2f} ç§’\n")
            f.write(f"ç›´æ¥APIå¹³å‡æ—¶é—´: {sum(direct_times)/len(direct_times):.2f} ç§’\n")
            f.write(f"æ—¶é—´å·®å¼‚: {sum(retrieval_times)/len(retrieval_times) - sum(direct_times)/len(direct_times):.2f} ç§’\n\n")
            
            f.write("2. ç­”æ¡ˆé•¿åº¦å¯¹æ¯”\n")
            f.write("-" * 30 + "\n")
            f.write(f"æ–‡çŒ®åº“æ£€ç´¢å¹³å‡é•¿åº¦: {sum(retrieval_lengths)/len(retrieval_lengths):.0f} å­—ç¬¦\n")
            f.write(f"ç›´æ¥APIå¹³å‡é•¿åº¦: {sum(direct_lengths)/len(direct_lengths):.0f} å­—ç¬¦\n")
            f.write(f"é•¿åº¦å·®å¼‚: {sum(retrieval_lengths)/len(retrieval_lengths) - sum(direct_lengths)/len(direct_lengths):.0f} å­—ç¬¦\n\n")
            
            f.write("3. å¼•ç”¨æ•°é‡å¯¹æ¯”\n")
            f.write("-" * 30 + "\n")
            f.write(f"æ–‡çŒ®åº“æ£€ç´¢å¹³å‡å¼•ç”¨: {sum(retrieval_citations)/len(retrieval_citations):.1f} ä¸ª\n")
            f.write(f"ç›´æ¥APIå¹³å‡å¼•ç”¨: {sum(direct_citations)/len(direct_citations):.1f} ä¸ª\n")
            f.write(f"å¼•ç”¨å·®å¼‚: {sum(retrieval_citations)/len(retrieval_citations) - sum(direct_citations)/len(direct_citations):.1f} ä¸ª\n\n")
            
            f.write("4. ä¸Šä¸‹æ–‡ç‰‡æ®µå¯¹æ¯”\n")
            f.write("-" * 30 + "\n")
            f.write(f"æ–‡çŒ®åº“æ£€ç´¢å¹³å‡ç‰‡æ®µ: {sum(retrieval_fragments)/len(retrieval_fragments):.1f} ä¸ª\n")
            f.write(f"ç›´æ¥APIå¹³å‡ç‰‡æ®µ: {sum(direct_fragments)/len(direct_fragments):.1f} ä¸ª\n")
            f.write(f"ç‰‡æ®µå·®å¼‚: {sum(retrieval_fragments)/len(retrieval_fragments) - sum(direct_fragments)/len(direct_fragments):.1f} ä¸ª\n\n")
            
            f.write("5. è¯¦ç»†å¯¹æ¯”æ•°æ®\n")
            f.write("-" * 30 + "\n")
            for item in self.comparison_data:
                f.write(f"\né—®é¢˜ {item['question_id']}:\n")
                f.write(f"  æ–‡çŒ®åº“æ£€ç´¢: {item['retrieval']['processing_time']:.2f}s, "
                       f"{item['retrieval']['answer_length']}å­—ç¬¦, "
                       f"{item['retrieval']['citation_count']}å¼•ç”¨, "
                       f"{item['retrieval']['context_fragments']}ç‰‡æ®µ\n")
                f.write(f"  ç›´æ¥API: {item['direct_api']['processing_time']:.2f}s, "
                       f"{item['direct_api']['answer_length']}å­—ç¬¦, "
                       f"{item['direct_api']['citation_count']}å¼•ç”¨, "
                       f"{item['direct_api']['context_fragments']}ç‰‡æ®µ\n")
        
        # ä¿å­˜JSONæ ¼å¼çš„å¯¹æ¯”æ•°æ®
        json_file = self.output_dir / "comparison_data.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.comparison_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“Š å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
    
    def generate_comparison_charts(self):
        """ç”Ÿæˆå¯¹æ¯”å›¾è¡¨"""
        if not self.comparison_data:
            print("âŒ æ²¡æœ‰å¯¹æ¯”æ•°æ®å¯ç”Ÿæˆå›¾è¡¨")
            return
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.style.use('default')
        sns.set_palette("husl")
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('æœ‰æ— æ–‡çŒ®åº“æ£€ç´¢åŠŸèƒ½å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
        
        # å‡†å¤‡æ•°æ®
        questions = [f"Q{i}" for i in range(1, len(self.comparison_data) + 1)]
        retrieval_times = [item["retrieval"]["processing_time"] for item in self.comparison_data]
        direct_times = [item["direct_api"]["processing_time"] for item in self.comparison_data]
        
        retrieval_lengths = [item["retrieval"]["answer_length"] for item in self.comparison_data]
        direct_lengths = [item["direct_api"]["answer_length"] for item in self.comparison_data]
        
        retrieval_citations = [item["retrieval"]["citation_count"] for item in self.comparison_data]
        direct_citations = [item["direct_api"]["citation_count"] for item in self.comparison_data]
        
        retrieval_fragments = [item["retrieval"]["context_fragments"] for item in self.comparison_data]
        direct_fragments = [item["direct_api"]["context_fragments"] for item in self.comparison_data]
        
        # 1. å¤„ç†æ—¶é—´å¯¹æ¯”
        x = range(len(questions))
        width = 0.35
        
        axes[0, 0].bar([i - width/2 for i in x], retrieval_times, width, label='æ–‡çŒ®åº“æ£€ç´¢', alpha=0.8)
        axes[0, 0].bar([i + width/2 for i in x], direct_times, width, label='ç›´æ¥API', alpha=0.8)
        axes[0, 0].set_xlabel('é—®é¢˜ç¼–å·')
        axes[0, 0].set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
        axes[0, 0].set_title('å¤„ç†æ—¶é—´å¯¹æ¯”')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(questions)
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. ç­”æ¡ˆé•¿åº¦å¯¹æ¯”
        axes[0, 1].bar([i - width/2 for i in x], retrieval_lengths, width, label='æ–‡çŒ®åº“æ£€ç´¢', alpha=0.8)
        axes[0, 1].bar([i + width/2 for i in x], direct_lengths, width, label='ç›´æ¥API', alpha=0.8)
        axes[0, 1].set_xlabel('é—®é¢˜ç¼–å·')
        axes[0, 1].set_ylabel('ç­”æ¡ˆé•¿åº¦ (å­—ç¬¦)')
        axes[0, 1].set_title('ç­”æ¡ˆé•¿åº¦å¯¹æ¯”')
        axes[0, 1].set_xticks(x)
        axes[0, 1].set_xticklabels(questions)
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. å¼•ç”¨æ•°é‡å¯¹æ¯”
        axes[1, 0].bar([i - width/2 for i in x], retrieval_citations, width, label='æ–‡çŒ®åº“æ£€ç´¢', alpha=0.8)
        axes[1, 0].bar([i + width/2 for i in x], direct_citations, width, label='ç›´æ¥API', alpha=0.8)
        axes[1, 0].set_xlabel('é—®é¢˜ç¼–å·')
        axes[1, 0].set_ylabel('å¼•ç”¨æ•°é‡')
        axes[1, 0].set_title('å¼•ç”¨æ•°é‡å¯¹æ¯”')
        axes[1, 0].set_xticks(x)
        axes[1, 0].set_xticklabels(questions)
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ä¸Šä¸‹æ–‡ç‰‡æ®µå¯¹æ¯”
        axes[1, 1].bar([i - width/2 for i in x], retrieval_fragments, width, label='æ–‡çŒ®åº“æ£€ç´¢', alpha=0.8)
        axes[1, 1].bar([i + width/2 for i in x], direct_fragments, width, label='ç›´æ¥API', alpha=0.8)
        axes[1, 1].set_xlabel('é—®é¢˜ç¼–å·')
        axes[1, 1].set_ylabel('ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°é‡')
        axes[1, 1].set_title('ä¸Šä¸‹æ–‡ç‰‡æ®µå¯¹æ¯”')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(questions)
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        chart_file = self.output_dir / "comparison_charts.png"
        plt.savefig(chart_file, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“ˆ å¯¹æ¯”å›¾è¡¨å·²ç”Ÿæˆ: {chart_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š å¯¹æ¯”åˆ†æè„šæœ¬")
    print("="*60)
    print("ğŸ” æ¯”è¾ƒæœ‰æ— æœ¬åœ°æ–‡çŒ®åº“æ£€ç´¢åŠŸèƒ½çš„å·®å¼‚")
    
    # åˆ›å»ºåˆ†æå™¨å¹¶è¿è¡Œå¯¹æ¯”
    analyzer = ComparisonAnalyzer()
    analyzer.compare_methods()


if __name__ == "__main__":
    main() 