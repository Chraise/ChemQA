#!/usr/bin/env python3
"""
å¿«é€Ÿæœ‰æœºç”µå‚¬åŒ–é—®ç­”æµ‹è¯•è„šæœ¬

æµ‹è¯•å‰3ä¸ªè‹±æ–‡çš„æœ‰æœºç”µå‚¬åŒ–é¢†åŸŸé—®é¢˜ï¼Œè·å–å›ç­”å¹¶è¿›è¡Œå¼•ç”¨åˆ†æã€‚
"""

import sys
import os
import json
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.qa_system.expert_system import ChemicalQAExpert
from src.qa_system.citation_analyzer import analyze_answer_citations


def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‰3ä¸ªé—®é¢˜"""
    
    # å®šä¹‰å‰3ä¸ªé—®é¢˜
    questions = [
        "What are the key mechanisms of CO2 electroreduction on copper-based catalysts?",
        "How does the coordination environment affect the performance of nickel-based electrocatalysts for alcohol oxidation?",
        "What are the recent advances in electrochemical C-H functionalization of aromatic compounds?"
    ]
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("quick_test_output")
    output_dir.mkdir(exist_ok=True)
    
    print("ğŸ§ª å¿«é€Ÿæœ‰æœºç”µå‚¬åŒ–é—®ç­”æµ‹è¯•")
    print("="*60)
    print(f"ğŸ“ æµ‹è¯• {len(questions)} ä¸ªé—®é¢˜")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    expert = ChemicalQAExpert()
    results = []
    
    for i, question in enumerate(questions, 1):
        print(f"\n{'='*60}")
        print(f"æµ‹è¯• {i}/3: {question}")
        print(f"{'='*60}")
        
        try:
            start_time = time.time()
            
            print("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
            
            # æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
            context = expert.retriever.retrieve_relevant_context(question, return_dict_list=True)
            
            # ç”ŸæˆåŸå§‹ç­”æ¡ˆ
            raw_answer = expert.generator.generate_answer(question, context)
            
            # åˆ†æå¼•ç”¨æƒ…å†µ
            print("æ­£åœ¨åˆ†æå¼•ç”¨æƒ…å†µ...")
            analysis_report = analyze_answer_citations(
                answer=raw_answer,
                context=context,
                print_report=False,
                save_to_file=False
            )
            
            # æ ¼å¼åŒ–ç­”æ¡ˆ
            formatted_response = expert.formatter.format(question, raw_answer, context)
            
            processing_time = time.time() - start_time
            
            # ä¿å­˜ç»“æœ
            result = {
                "question_id": i,
                "question": question,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat(),
                "citation_analysis": analysis_report,
                "context_count": len(context),
                "answer_length": len(raw_answer)
            }
            
            # ä¿å­˜ç­”æ¡ˆæ–‡ä»¶
            answer_file = output_dir / f"answer_{i:02d}.md"
            with open(answer_file, 'w', encoding='utf-8') as f:
                f.write(formatted_response)
            
            # ä¿å­˜å¼•ç”¨åˆ†æ
            analysis_file = output_dir / f"citation_analysis_{i:02d}.txt"
            with open(analysis_file, 'w', encoding='utf-8') as f:
                f.write(f"Question {i}: {question}\n")
                f.write("="*50 + "\n\n")
                f.write(f"Processing Time: {processing_time:.2f} seconds\n")
                f.write(f"Context Chunks: {len(context)}\n")
                f.write(f"Answer Length: {len(raw_answer)} characters\n\n")
                f.write("Citation Analysis:\n")
                f.write(f"- Total Context Chunks: {analysis_report['total_context_chunks']}\n")
                f.write(f"- Cited Chunks: {analysis_report['citation_coverage']['cited_count']}\n")
                f.write(f"- Citation Coverage: {analysis_report['citation_coverage']['coverage_percentage']}%\n")
                f.write(f"- Unused Chunks: {analysis_report['citation_coverage']['unused_count']}\n\n")
                
                if analysis_report['cited_chunks_analysis']['cited_chunks']:
                    f.write("Cited Chunks Details:\n")
                    for j, chunk in enumerate(analysis_report['cited_chunks_analysis']['cited_chunks'], 1):
                        f.write(f"{j}. Source: {chunk['source']}\n")
                        f.write(f"   Chunk Index: {chunk['chunk_index']}\n")
                        f.write(f"   Citation Count: {chunk['citation_count']}\n")
                        f.write(f"   Content Preview: {chunk['text_preview']}\n\n")
            
            results.append(result)
            
            print(f"âœ… æµ‹è¯• {i} å®Œæˆ")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            print(f"   ä¸Šä¸‹æ–‡ç‰‡æ®µ: {len(context)} ä¸ª")
            print(f"   å¼•ç”¨è¦†ç›–ç‡: {analysis_report['citation_coverage']['coverage_percentage']}%")
            
        except Exception as e:
            print(f"âŒ æµ‹è¯• {i} å¤±è´¥: {str(e)}")
            results.append({
                "question_id": i,
                "question": question,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            })
        
        # ç­‰å¾…2ç§’
        if i < len(questions):
            print("â³ ç­‰å¾…2ç§’åç»§ç»­...")
            time.sleep(2)
    
    # ä¿å­˜æ±‡æ€»ç»“æœ
    successful_tests = [r for r in results if 'error' not in r]
    failed_tests = [r for r in results if 'error' in r]
    
    if successful_tests:
        avg_processing_time = sum(r['processing_time'] for r in successful_tests) / len(successful_tests)
        avg_citation_coverage = sum(r['citation_analysis']['citation_coverage']['coverage_percentage'] for r in successful_tests) / len(successful_tests)
    else:
        avg_processing_time = 0
        avg_citation_coverage = 0
    
    # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
    summary_file = output_dir / "quick_test_summary.txt"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("å¿«é€Ÿæµ‹è¯•æ±‡æ€»æŠ¥å‘Š\n")
        f.write("="*40 + "\n\n")
        f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æˆåŠŸæµ‹è¯•: {len(successful_tests)}/3\n")
        f.write(f"å¤±è´¥æµ‹è¯•: {len(failed_tests)}/3\n")
        f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f} ç§’\n")
        f.write(f"å¹³å‡å¼•ç”¨è¦†ç›–ç‡: {avg_citation_coverage:.2f}%\n\n")
        
        for result in results:
            f.write(f"é—®é¢˜ {result['question_id']}: {result['question']}\n")
            if 'error' in result:
                f.write(f"çŠ¶æ€: å¤±è´¥ - {result['error']}\n")
            else:
                f.write(f"çŠ¶æ€: æˆåŠŸ\n")
                f.write(f"å¤„ç†æ—¶é—´: {result['processing_time']} ç§’\n")
                f.write(f"å¼•ç”¨è¦†ç›–ç‡: {result['citation_analysis']['citation_coverage']['coverage_percentage']}%\n")
            f.write("\n")
    
    print(f"\nğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“Š æˆåŠŸ: {len(successful_tests)}/3")
    print(f"ğŸ“Š å¤±è´¥: {len(failed_tests)}/3")
    print(f"ğŸ“Š å¹³å‡å¼•ç”¨è¦†ç›–ç‡: {avg_citation_coverage:.2f}%")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_dir}")


if __name__ == "__main__":
    quick_test() 