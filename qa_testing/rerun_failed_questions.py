#!/usr/bin/env python3
"""
é‡æ–°è¿è¡Œå¤±è´¥é—®é¢˜çš„è„šæœ¬

ä¸“é—¨é‡æ–°è¿è¡Œé—®é¢˜7å’Œ10ï¼Œå¹¶æ›´æ–°æ±‡æ€»æ–‡ä»¶ã€‚
"""

import sys
import os
import json
import time
from datetime import datetime
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.qa_system.expert_system import ChemicalQAExpert
from src.qa_system.citation_analyzer import CitationAnalyzer


class FailedQuestionRerunner:
    """å¤±è´¥é—®é¢˜é‡æ–°è¿è¡Œå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é‡æ–°è¿è¡Œå™¨"""
        self.expert_system = ChemicalQAExpert()
        self.citation_analyzer = CitationAnalyzer()
        
        # å®šä¹‰è¾“å‡ºç›®å½•
        self.output_dir = Path("qa_testing/test_output")
        
        # å®šä¹‰éœ€è¦é‡æ–°è¿è¡Œçš„é—®é¢˜
        self.failed_questions = [7, 10]
        
        # å®šä¹‰é—®é¢˜åˆ—è¡¨ï¼ˆä¸åŸå§‹æµ‹è¯•ç›¸åŒï¼‰
        self.questions = [
            "What are the key mechanisms of CO2 electroreduction on copper-based catalysts?",
            "How does the coordination environment affect the performance of nickel-based electrocatalysts for alcohol oxidation?",
            "What are the recent advances in electrochemical C-H functionalization of aromatic compounds?",
            "How can we improve the selectivity of electrochemical reduction of carbonyl compounds?",
            "What role do electrolyte additives play in organic electrocatalysis?",
            "How does the surface structure of platinum catalysts influence organic molecule oxidation?",
            "What are the challenges and solutions for electrochemical synthesis of heterocyclic compounds?",
            "How can we achieve high current density in organic electrosynthesis?",
            "What are the mechanistic insights into electrochemical oxidation of biomass-derived compounds?",
            "How does the pH of electrolyte affect the reaction pathways in organic electrocatalysis?"
        ]
    
    def load_existing_summary(self) -> dict:
        """åŠ è½½ç°æœ‰çš„æ±‡æ€»æ–‡ä»¶"""
        summary_file = self.output_dir / "test_summary.json"
        if summary_file.exists():
            with open(summary_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def run_single_question(self, question_id: int) -> dict:
        """è¿è¡Œå•ä¸ªé—®é¢˜"""
        question = self.questions[question_id - 1]  # è½¬æ¢ä¸º0ç´¢å¼•
        
        print(f"\n{'='*80}")
        print(f"é‡æ–°è¿è¡Œé—®é¢˜ {question_id}/10: {question}")
        print(f"{'='*80}")
        
        try:
            # è®°å½•å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            print("æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
            
            # æ£€ç´¢ä¸Šä¸‹æ–‡
            context = self.expert_system.retriever.retrieve_relevant_context(question, return_dict_list=True)
            # ä½¿ç”¨ä¸“å®¶ç³»ç»Ÿç”Ÿæˆç­”æ¡ˆ
            answer = self.expert_system.answer_query(question, analyze_citations=False)
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # åˆ†æå¼•ç”¨
            print("æ­£åœ¨åˆ†æå¼•ç”¨...")
            citation_analysis = self.citation_analyzer.analyze_citations(answer, context)
            
            # ä¿å­˜ç­”æ¡ˆæ–‡ä»¶
            answer_file = self.output_dir / f"answer_{question_id:02d}.md"
            with open(answer_file, 'w', encoding='utf-8') as f:
                f.write(f"# æœ‰æœºç”µå‚¬åŒ–é—®ç­” - é—®é¢˜ {question_id}\n\n")
                f.write(f"**é—®é¢˜ï¼š** {question}\n\n")
                f.write(f"**å›ç­”æ—¶é—´ï¼š** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**å¤„ç†æ—¶é—´ï¼š** {processing_time:.2f} ç§’\n")
                f.write(f"**æ–¹æ³•ï¼š** æœ¬åœ°æ–‡çŒ®åº“æ£€ç´¢ + ä¸“å®¶ç³»ç»Ÿ\n\n")
                f.write(f"## å›ç­”å†…å®¹\n\n{answer}\n\n")
                f.write("---\n")
                f.write("*æ­¤å›ç­”åŸºäºæœ¬åœ°æ–‡çŒ®åº“æ£€ç´¢ç”Ÿæˆï¼ŒåŒ…å«ç›¸å…³æ–‡çŒ®å¼•ç”¨ã€‚*")
            
            # ä¿å­˜å¼•ç”¨åˆ†æ
            citation_file = self.output_dir / f"citation_analysis_{question_id:02d}.txt"
            with open(citation_file, 'w', encoding='utf-8') as f:
                f.write(f"å¼•ç”¨åˆ†ææŠ¥å‘Š - é—®é¢˜ {question_id}\n")
                f.write("="*50 + "\n\n")
                f.write(f"é—®é¢˜: {question}\n\n")
                f.write(f"å¼•ç”¨æ•°é‡: {citation_analysis['cited_chunks_analysis']['cited_count']}\n")
                f.write(f"ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°é‡: {citation_analysis['total_context_chunks']}\n\n")
                
                if citation_analysis['cited_chunks_analysis']['cited_chunks']:
                    f.write("è¯¦ç»†å¼•ç”¨ä¿¡æ¯:\n")
                    for i, chunk in enumerate(citation_analysis['cited_chunks_analysis']['cited_chunks'], 1):
                        f.write(f"\n{i}. æ¥æº: {chunk['source']}  ç‰‡æ®µå·: {chunk['chunk_index']}\n")
                        f.write(f"   å†…å®¹é¢„è§ˆ: {chunk['text_preview']}\n")
                else:
                    f.write("æœªå‘ç°å¼•ç”¨æ ‡è®°ã€‚\n")
            
            # è¿”å›ç»“æœ
            result = {
                "question_id": question_id,
                "question": question,
                "processing_time": round(processing_time, 2),
                "timestamp": datetime.now().isoformat(),
                "answer_length": len(answer),
                "answer": answer,
                "citation_count": citation_analysis['cited_chunks_analysis']['cited_count'],
                "context_fragments": citation_analysis['total_context_chunks'],
                "method": "retrieval_augmented"
            }
            
            print(f"âœ… é—®é¢˜ {question_id} é‡æ–°è¿è¡Œå®Œæˆ")
            print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            print(f"   ç­”æ¡ˆé•¿åº¦: {len(answer)} å­—ç¬¦")
            print(f"   å¼•ç”¨æ•°é‡: {citation_analysis['cited_chunks_analysis']['cited_count']}")
            
            return result
            
        except Exception as e:
            print(f"âŒ é—®é¢˜ {question_id} é‡æ–°è¿è¡Œå¤±è´¥: {str(e)}")
            return {
                "question_id": question_id,
                "question": question,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
                "method": "retrieval_augmented"
            }
    
    def update_summary_files(self, new_results: list):
        """æ›´æ–°æ±‡æ€»æ–‡ä»¶"""
        print("ğŸ“ æ­£åœ¨æ›´æ–°æ±‡æ€»æ–‡ä»¶...")
        
        # è¯»å–ç°æœ‰çš„è¯¦ç»†ç»“æœ
        detailed_results_file = self.output_dir / "detailed_results.json"
        if detailed_results_file.exists():
            with open(detailed_results_file, 'r', encoding='utf-8') as f:
                detailed_results = json.load(f)
        else:
            detailed_results = []
        
        # æ›´æ–°å¤±è´¥é—®é¢˜çš„ç»“æœ
        for new_result in new_results:
            question_id = new_result['question_id']
            # æ‰¾åˆ°å¯¹åº”çš„ç»“æœå¹¶æ›´æ–°
            for i, result in enumerate(detailed_results):
                if result['question_id'] == question_id:
                    detailed_results[i] = new_result
                    break
            else:
                # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œæ·»åŠ æ–°ç»“æœ
                detailed_results.append(new_result)
        
        # ä¿å­˜æ›´æ–°åçš„è¯¦ç»†ç»“æœ
        with open(detailed_results_file, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)
        
        # é‡æ–°è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        successful_tests = [r for r in detailed_results if 'error' not in r]
        failed_tests = [r for r in detailed_results if 'error' in r]
        
        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        avg_processing_time = sum(r.get('processing_time', 0) for r in successful_tests) / len(successful_tests) if successful_tests else 0
        avg_answer_length = sum(r.get('answer_length', 0) for r in successful_tests) / len(successful_tests) if successful_tests else 0
        avg_citation_count = sum(r.get('citation_count', 0) for r in successful_tests) / len(successful_tests) if successful_tests else 0
        avg_context_fragments = sum(r.get('context_fragments', 0) for r in successful_tests) / len(successful_tests) if successful_tests else 0
        
        # æ›´æ–°JSONæ±‡æ€»æ–‡ä»¶
        summary_json_file = self.output_dir / "test_summary.json"
        summary_data = {
            "total_questions": len(detailed_results),
            "successful_questions": len(successful_tests),
            "failed_questions": len(failed_tests),
            "average_processing_time": round(avg_processing_time, 2),
            "average_answer_length": round(avg_answer_length, 1),
            "average_citation_count": round(avg_citation_count, 2),
            "average_context_fragments": round(avg_context_fragments, 2),
            "detailed_results": detailed_results
        }
        
        with open(summary_json_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        # å†™å…¥æ–‡æœ¬æŠ¥å‘Š
        summary_report_file = self.output_dir / "test_summary_report.txt"
        with open(summary_report_file, 'w', encoding='utf-8') as f:
            f.write(f"æœ‰æœºç”µå‚¬åŒ–é—®ç­”æµ‹è¯•æ±‡æ€»æŠ¥å‘Š\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"æ€»é—®é¢˜æ•°: {len(detailed_results)}\n")
            f.write(f"æˆåŠŸé—®é¢˜æ•°: {len(successful_tests)}\n")
            f.write(f"å¤±è´¥é—®é¢˜æ•°: {len(failed_tests)}\n\n")
            f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f} ç§’\n")
            f.write(f"å¹³å‡ç­”æ¡ˆé•¿åº¦: {avg_answer_length:.1f} å­—ç¬¦\n")
            f.write(f"å¹³å‡å¼•ç”¨ç‰‡æ®µæ•°: {avg_citation_count:.2f} ä¸ª\n")
            f.write(f"å¹³å‡ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°: {avg_context_fragments:.2f} ä¸ª\n\n")
            f.write("è¯¦ç»†ç»“æœï¼š\n")
            for result in detailed_results:
                f.write(f"\né—®é¢˜ {result['question_id']}: {result['question']}\n")
                f.write(f"çŠ¶æ€: {'æˆåŠŸ' if 'error' not in result else 'å¤±è´¥'}\n")
                f.write(f"å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f} ç§’\n")
                f.write(f"ç­”æ¡ˆé•¿åº¦: {result.get('answer_length', 0):.1f} å­—ç¬¦\n")
                f.write(f"å¼•ç”¨æ•°é‡: {result.get('citation_count', 0)} ä¸ª\n")
                f.write(f"ä¸Šä¸‹æ–‡ç‰‡æ®µæ•°: {result.get('context_fragments', 0)} ä¸ª\n")
                if 'error' in result:
                    f.write(f"é”™è¯¯ä¿¡æ¯: {result['error']}\n")
                f.write("-" * 50)
        
        print("âœ… æ±‡æ€»æ–‡ä»¶æ›´æ–°å®Œæˆ")
    
    def run_failed_questions(self):
        """è¿è¡Œå¤±è´¥çš„é—®é¢˜"""
        print("ğŸ”„ é‡æ–°è¿è¡Œå¤±è´¥é—®é¢˜")
        print("="*60)
        print(f"ğŸ“ éœ€è¦é‡æ–°è¿è¡Œçš„é—®é¢˜: {self.failed_questions}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        
        new_results = []
        
        for question_id in self.failed_questions:
            result = self.run_single_question(question_id)
            new_results.append(result)
            
            # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
            if question_id != self.failed_questions[-1]:
                print("â³ ç­‰å¾…5ç§’åç»§ç»­ä¸‹ä¸€ä¸ªé—®é¢˜...")
                time.sleep(5)
        
        # æ›´æ–°æ±‡æ€»æ–‡ä»¶
        self.update_summary_files(new_results)
        
        # æ‰“å°æ±‡æ€»ä¿¡æ¯
        successful_reruns = [r for r in new_results if 'error' not in r]
        failed_reruns = [r for r in new_results if 'error' in r]
        
        print(f"\nğŸ“ˆ é‡æ–°è¿è¡Œæ±‡æ€»:")
        print(f"   æˆåŠŸ: {len(successful_reruns)}/{len(self.failed_questions)}")
        print(f"   å¤±è´¥: {len(failed_reruns)}/{len(self.failed_questions)}")
        
        if failed_reruns:
            print(f"\nâŒ ä»ç„¶å¤±è´¥çš„é—®é¢˜:")
            for result in failed_reruns:
                print(f"   é—®é¢˜ {result['question_id']}: {result['error']}")
        
        print(f"\nğŸ‰ é‡æ–°è¿è¡Œå®Œæˆï¼")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ å¤±è´¥é—®é¢˜é‡æ–°è¿è¡Œè„šæœ¬")
    print("="*60)
    print("ğŸ”§ ä¸“é—¨å¤„ç†APIè¶…æ—¶çš„é—®é¢˜7å’Œ10")
    
    # åˆ›å»ºé‡æ–°è¿è¡Œå™¨å¹¶æ‰§è¡Œ
    rerunner = FailedQuestionRerunner()
    rerunner.run_failed_questions()


if __name__ == "__main__":
    main() 